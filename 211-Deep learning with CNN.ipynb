{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"211-Deep learning with CNN.ipynb","provenance":[],"collapsed_sections":["nH5xzZMG0KDe","xU-6g5Dn0KDk","4X_0Esbb0KDm","GAYK8PCb0KDm","Krs886i30KDn"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"w8IsWLkt0KDT"},"source":["# CNN"]},{"cell_type":"code","metadata":{"id":"yqy2W8rY1_U-"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","basicpath = '/content/drive/MyDrive/LG_DIC_lecture/2일차/실습'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NVtzpFHG0KDW"},"source":["import numpy as np\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import matplotlib.pyplot as plt\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OS5BXN7N0KDW"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CjSbFn080KDX"},"source":["path = os.path.join(basicpath, 'Dataset/Classification/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_oxaDMKK0KDX"},"source":["## CIFAR Image"]},{"cell_type":"code","metadata":{"id":"S8foUGDK0KDX"},"source":["from IPython.display import Image\n","Image(basicpath + 'Image/cifar10.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nO2nULec0KDY"},"source":["## CIFAR data import"]},{"cell_type":"markdown","metadata":{"id":"ZQd_0fNR0KDY"},"source":["#### OFFline pickle data"]},{"cell_type":"code","metadata":{"id":"Bw-yQ6jO0KDY"},"source":["# def unpickle(file):\n","#     with open(file, 'rb') as fo:\n","#         dict = pickle.load(fo, encoding='bytes')\n","#     return dict\n","# data = unpickle(os.path.join(os.path.join(path, 'cifar-10-batches-py') ,'/data_batch_1'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OxsckuY70KDZ"},"source":["#### Online PIL image data"]},{"cell_type":"code","metadata":{"id":"zPI0s12G0KDZ"},"source":["# # For online situation\n","# trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","#                                         download=True, transform=transform)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZjiZYZDV0KDZ"},"source":["#### OFFline PIL data"]},{"cell_type":"code","metadata":{"id":"cRNHzjme0KDa"},"source":["# OFFline PIL data\n","trainset = torchvision.datasets.CIFAR10(root=path, train=True, \n","                                        download=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mghM9nf_0KDa"},"source":["classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SWjekTV90KDa"},"source":["for i in range(5):\n","    index = np.random.randint(len(trainset), dtype=int)\n","    image, label = trainset[index]\n","    image = image.resize((128, 128))\n","    display(image)\n","    print(classes[label])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jTqp7I_l0KDb"},"source":["### Transform PIL data to torch data and normalization"]},{"cell_type":"code","metadata":{"id":"PKxjzaQc0KDc"},"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root=path, train=True,\n","                                        download=False, transform=transform)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"htUGKwL90KDc"},"source":["a, _ =trainset[0]\n","a"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"21hFMn5x0KDd"},"source":["### Make Dataloader"]},{"cell_type":"code","metadata":{"id":"O2nW87_80KDd"},"source":["trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n","                                          shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JUdlo5UU0KDe"},"source":["## Learning with CNN - Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"id":"nH5xzZMG0KDe"},"source":["#### CNN: Convolution - (padding) - ReLU - Pooling layer로 이루어진 일련의 layer가 포함된 Network  \n","     인접 픽셀간의 상관관계를 고려한 Network 형태"]},{"cell_type":"markdown","metadata":{"id":"LPSymvZJ0KDe"},"source":["### Convolution layer"]},{"cell_type":"code","metadata":{"id":"3O6-k13F0KDf"},"source":["from IPython.display import Image\n","Image(basicpath + 'Image/convolution.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"au7bDSml0KDf"},"source":["### Padding layer"]},{"cell_type":"code","metadata":{"id":"f7Z2JzCY0KDf"},"source":["from IPython.display import Image\n","Image(basicpath + 'Image/padding.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h2J9chPT0KDf"},"source":["### Pooling layer"]},{"cell_type":"code","metadata":{"id":"2dn0DE8t0KDf"},"source":["from IPython.display import Image\n","Image(basicpath + 'Image/pooling.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KL3Q8Oks0KDg"},"source":["## CNN model"]},{"cell_type":"code","metadata":{"id":"X0ZZiMQt0KDg"},"source":["from IPython.display import Image\n","Image(basicpath + 'Image/CNN.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"up-OrYIy0KDg"},"source":["from IPython.display import Image\n","Image(basicpath + 'Image/CNN_layers.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZTtqqS2U0KDg"},"source":["## Define Model "]},{"cell_type":"code","metadata":{"id":"1ZPts_z40KDh"},"source":["import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ysqa60uj0KDh"},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        \n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 16 * 5 * 5)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","net = Net()\n","net.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q9crB2ol0KDh"},"source":["def conv_block(in_dim, out_dim):\n","    model = nn.Sequential(\n","        nn.Conv2d(in_dim, out_dim, kernel_size = 5), \n","        nn.ReLU(), \n","        nn.MaxPool2d(2, 2)\n","    )\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_fY6mo50KDi"},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.feature = nn.Sequential(\n","            conv_block(3, 6), \n","            conv_block(6, 16)\n","        )\n","        \n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","#         x = self.pool(F.relu(self.conv1(x)))\n","        \n","#         x = self.conv1(x)\n","#         x = self.pool(F.relu(self.conv2(x)))\n","        x = self.feature(x)\n","        x = x.view(-1, 16 * 5 * 5)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","net = Net()\n","net.to(device)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qQ-FJR_E0KDi"},"source":["## Learning the model"]},{"cell_type":"code","metadata":{"id":"e57FDea60KDi"},"source":["learning_rate = 0.001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jtOwRCKk0KDj"},"source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = optim.Adam(net.parameters(), lr = learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ktffz1G0KDj"},"source":["epochs = 20"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CvTbsBcj0KDj"},"source":["for epoch in range(epochs):\n","    running_cost = 0.0\n","\n","    for step, (batch_data) in enumerate(trainloader):\n","        batch_x, batch_y = batch_data[0].to(device), batch_data[1].to(device)\n","        \n","        optimizer.zero_grad()\n","        \n","        outputs = net(batch_x)\n","        cost = criterion(outputs, batch_y)\n","\n","        cost.backward()\n","        optimizer.step()\n","        \n","        running_cost += cost.item()\n","        if step % 2000 == 1999:\n","            print('[%d, %5d] cost: %.3f' % (epoch + 1, step + 1, running_cost / 2000))\n","            running_cost = 0.0\n","            "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Af4W0z0u0KDk"},"source":["## 정확도 판단"]},{"cell_type":"markdown","metadata":{"id":"xU-6g5Dn0KDk"},"source":["#### Test dataset import"]},{"cell_type":"code","metadata":{"id":"y6G5s5EL0KDk"},"source":["testset = torchvision.datasets.CIFAR10(root=path, train=False,\n","                                        download=False, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=len(testset),\n","                                          shuffle=False, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5zoA-ocH0KDl"},"source":["### Confusion matrix and scores"]},{"cell_type":"code","metadata":{"id":"PMQkeQqJ0KDl"},"source":["test_iter = iter(testloader)\n","test_x, test_labels = test_iter.next()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uuwo3_lE0KDl"},"source":["outputs = net(test_x.to(device))\n","_, predicted = torch.max(outputs, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kP--XAir0KDl"},"source":["predicted"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4X_0Esbb0KDm"},"source":["#### Confusion matrix"]},{"cell_type":"code","metadata":{"id":"Ka7GIS0O0KDm"},"source":["from sklearn.metrics import confusion_matrix\n","predicted = predicted.cpu()\n","print(confusion_matrix(test_labels, predicted))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GAYK8PCb0KDm"},"source":["#### Precision"]},{"cell_type":"code","metadata":{"id":"LjHVl42H0KDm"},"source":["from sklearn.metrics import precision_score\n","print(precision_score(test_labels, predicted, average=None))\n","print(precision_score(test_labels, predicted, average='weighted'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Krs886i30KDn"},"source":["#### Recall"]},{"cell_type":"code","metadata":{"id":"Uavx6F6Q0KDn"},"source":["from sklearn.metrics import recall_score\n","print(recall_score(test_labels, predicted, average=None))\n","print(recall_score(test_labels, predicted, average='weighted'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QEpfRnYv6Y79"},"source":[""],"execution_count":null,"outputs":[]}]}